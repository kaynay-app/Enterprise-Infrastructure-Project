# Enterprise-Infrastructure-Project
Cloud/On-premise enterprise virtual environment infrastructure project with High Availability features

# ğŸ—ï¸ Private Cloud Infrastructure Lab (On-Prem / Virtual)

This project documents the **planning, build, and upgrade of a complete VMware-based on-premises virtual datacenter**, built using VMware Workstation as the foundation. It includes domain controllers, DNS, WSUS, iSCSI shared storage, domain-joined ESXi hosts and vCenter, and PowerShell-based VM alerting.

The lab simulates a **resilient private cloud environment** and is used to test system recovery, infrastructure upgrades, automated monitoring, and VM migrations.

---

## ğŸ“‹ Contents

- ğŸ—ºï¸ Network & Infrastructure Topology
- ğŸ–¥ï¸ ESXi Host Deployment & Upgrade Process
- ğŸ§  vCenter Recovery & Cold Migration Strategy
- ğŸ–§ Shared Storage Setup (iSCSI via Windows Server)
- ğŸ§± Active Directory + DNS + WSUS Architecture
- ğŸ”„ Live & Cold VM Migration Testing (vMotion)
- ğŸ’¬ PowerShell-based Alerting via SMTP
- âš ï¸ Troubleshooting Logs
- ğŸ“š Lessons Learned & Next Steps

---

## ğŸ§° Technologies Used

- VMware ESXi 7.0U3s (nested in VMware Workstation)
- vCenter Server Appliance (VCSA)
- Windows Server 2019 / 2022
- Active Directory Domain Services (ADDS)
- DNS, WSUS (KLM-DC02), iSCSI Target (KLM-DC01)
- iSCSI Shared Storage (MS iSCSI Target on Server)
- PowerShell (monitoring & alerting scripts)
- SMTP (email alerting for VM outages)
- VMware Workstation Pro
- GitHub (project documentation)

---

## ğŸ§  Active Directory & Domain Services

- `KLM-DC01`: Primary domain controller  
  - Provides **iSCSI shared storage** via MS iSCSI Target  
  - Hosts **DNS** services  

- `KLM-DC02`: Secondary DC  
  - Runs **Windows Server Update Services (WSUS)**  
  - DNS server for fault tolerance  

- `KLM-DC03`: Tertiary DC  
  - Provides **additional DNS & AD** services  

All components are part of the domain `klm.king.klm`.

---

## ğŸ“¦ vCenter & ESXi

- vCenter (KLMVCENTER01) and all ESXi hosts are **domain joined**
- Hosts were **upgraded** to ESXi 7.0U3s after deployment with manual .zip file upgrade 
- **Cold migration** used as fallback when vMotion failed
- vMotion issues resolved by aligning **network policies** across vSwitches

---

## ğŸ›ï¸ Monitoring & Alerting

- Custom **PowerShell scripts** monitor VM power states
- If a VM is **down or unresponsive**, a script triggers:
  - An alert via **SMTP email**
  - Optional log output or escalation steps

---

## ğŸ”„ VM Migration Example

VMs (including vCenter) were tested for:
- Live migration (vMotion) between upgraded hosts
- Cold migration fallback when vMotion failed
- Networking compatibility issues across ESXi hosts
- DNS resolution post-migration

---

## ğŸ›  Troubleshooting Highlights

- Resolved low memory issues (`stagebootbank` ramdisk)
- Addressed failed `lwsmd` process after upgrade
- Manually powered off VMs from CLI when unresponsive
- Re-registered VMs using `vim-cmd` after migration failures
- Updated CPU core settings to bypass ESXi hardware warnings in nested lab
- Performed upgrades with Image Depot baselines and manual .zip upgrades

---

## ğŸ“ Status

âœ… Fully functional & documented  
- Enabled vSphere HA and DRS
- Integrated syslog and centralized logging  
- Deployed Linux and Windows workload VMs

---

## ğŸ’¡ Why This Project?

-To simulate a **production-grade private cloud lab**, replicating enterprise-level systems for:
- Disaster recovery testing with backups and snapshots 
- Infrastructure automation  
- Host patching and upgrade paths  
- AD-integrated VMware infrastructure  
- Hands-on experience with core IT systems
